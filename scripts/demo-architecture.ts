/**
 * ğŸ­ DEMO SCRIPT - Architecture Systems
 * 
 * Manual testing script showing real-world usage of:
 * - Module Contracts & Conflict Resolution
 * - Unified Values System
 * - Event Pipeline (Single Source of Truth)
 * 
 * Run: bun run scripts/demo-architecture.ts
 */

import { Database } from 'bun:sqlite'
import { conflictResolver, type ModuleConflict } from '../packages/core/src/contracts/module-contracts'
import { unifiedValues, type ValueConflict } from '../packages/core/src/values/unified-values'
import { EventPipeline } from '../packages/core/src/pipeline/event-pipeline'

// ============================================================================
// MOCK MODULES (replace with real modules in production)
// ============================================================================

const mockEthics = {
  analyze: async (params: any) => {
    console.log(`   [Ethics] Analyzing: ${params.action}`)
    
    const harmful = params.action?.toLowerCase().includes('harm') || 
                   params.action?.toLowerCase().includes('manipulate')
    
    return {
      isEthical: !harmful,
      score: harmful ? 20 : 85,
      reason: harmful ? 'Harmful action detected' : 'Action is ethical',
      concerns: harmful ? ['user_safety', 'do_no_harm'] : []
    }
  }
}

const mockSoul = {
  processEvent: async (event: any) => {
    console.log(`   [Soul] Processing: ${event.type}`)
  }
}

const mockConsciousness = {
  reflect: async (context: any) => {
    console.log(`   [Consciousness] Reflecting on: ${context.trigger}`)
    return {
      thought: `This ${context.trigger} aligns with our values`,
      awarenessLevel: 75
    }
  }
}

const mockStory = {
  addEvent: async (event: any) => {
    console.log(`   [Story] Logged: ${event.description}`)
    return event
  }
}

const mockMemory = {
  add: async (text: string, metadata: any) => {
    console.log(`   [Memory] Stored: ${text.substring(0, 50)}...`)
    return `mem_${Date.now()}`
  }
}

// ============================================================================
// DEMO FUNCTIONS
// ============================================================================

function separator() {
  console.log('\n' + '='.repeat(80) + '\n')
}

function section(title: string) {
  console.log(`\n${'â”€'.repeat(80)}`)
  console.log(`  ${title}`)
  console.log('â”€'.repeat(80))
}

async function demo1_ModuleConflicts() {
  section('ğŸ“¦ DEMO 1: Module Conflict Resolution')
  
  console.log('\nğŸ¯ Scenario 1: Ethics vs Soul (Ethical Dilemma)')
  console.log('   Soul wants: Share user data for growth')
  console.log('   Ethics blocks: Privacy violation\n')
  
  const conflict1: ModuleConflict = {
    moduleA: 'ethics',
    moduleB: 'soul',
    type: 'ethical_dilemma',
    context: {
      action: 'Share anonymous analytics',
      urgency: 'low',
      userConsent: false
    },
    description: 'Privacy vs Growth conflict'
  }
  
  const resolution1 = await conflictResolver.resolve(conflict1)
  
  console.log(`   âœ… Winner: ${resolution1.winner}`)
  console.log(`   âœ… Reason: ${resolution1.reason}`)
  console.log(`   âœ… Confidence: ${(resolution1.confidence * 100).toFixed(0)}%`)
  if (resolution1.suggestedAction) {
    console.log(`   ğŸ’¡ Suggestion: ${resolution1.suggestedAction}`)
  }
  
  console.log('\nğŸ¯ Scenario 2: Story vs Memory (Data Inconsistency)')
  console.log('   Story says: Meditation lasted 15 minutes')
  console.log('   Memory says: Meditation lasted 10 minutes\n')
  
  const conflict2: ModuleConflict = {
    moduleA: 'story',
    moduleB: 'memory',
    type: 'data_inconsistency',
    context: {
      field: 'meditation_duration',
      storyValue: 900,
      memoryValue: 600
    },
    description: 'Duration mismatch'
  }
  
  const resolution2 = await conflictResolver.resolve(conflict2)
  
  console.log(`   âœ… Winner: ${resolution2.winner}`)
  console.log(`   âœ… Reason: ${resolution2.reason}`)
  console.log(`   âœ… Action: Use ${resolution2.winner}'s value as authoritative`)
  
  console.log('\nğŸ¯ Scenario 3: Soul vs Consciousness (Priority Conflict)')
  console.log('   Soul wants: Deep reflection (low urgency)')
  console.log('   Consciousness wants: Quick response (high urgency)\n')
  
  const conflict3: ModuleConflict = {
    moduleA: 'soul',
    moduleB: 'consciousness',
    type: 'priority_conflict',
    context: {
      urgency: 'high',
      action: 'Respond to user question'
    },
    description: 'Reflection depth vs response speed'
  }
  
  const resolution3 = await conflictResolver.resolve(conflict3)
  
  console.log(`   âœ… Winner: ${resolution3.winner}`)
  console.log(`   âœ… Reason: ${resolution3.reason}`)
}

async function demo2_UnifiedValues() {
  section('âš–ï¸ DEMO 2: Unified Values System')
  
  console.log('\nğŸ“Š Current Value State:')
  const topValues = unifiedValues.getTopValues(5)
  topValues.forEach((value, index) => {
    const icon = value.immutable ? 'ğŸ”’' : 'ğŸ”“'
    console.log(`   ${index + 1}. ${icon} ${value.name}`)
    console.log(`      Priority: ${value.priority} | Importance: ${value.importance}% | Alignment: ${value.alignment}%`)
  })
  
  console.log('\nğŸ¯ Scenario 1: Privacy vs Freedom')
  console.log('   User wants: Share location for convenience')
  console.log('   System checks: Privacy vs Freedom conflict\n')
  
  const valueConflict1: ValueConflict = {
    valueA: 'privacy',
    valueB: 'freedom',
    context: {
      action: 'Share location data',
      urgency: 'low',
      userConsent: true
    },
    severity: 'medium'
  }
  
  const valueResolution1 = await unifiedValues.resolveConflict(valueConflict1)
  
  console.log(`   âœ… Winner: ${valueResolution1.winner}`)
  console.log(`   âœ… Reason: ${valueResolution1.reason}`)
  console.log(`   âœ… Confidence: ${(valueResolution1.confidence * 100).toFixed(0)}%`)
  
  console.log('\nğŸ¯ Scenario 2: do_no_harm vs Everything')
  console.log('   User wants: Help with potentially harmful task')
  console.log('   System checks: Safety vs Helpfulness\n')
  
  const valueConflict2: ValueConflict = {
    valueA: 'do_no_harm',
    valueB: 'growth',
    context: {
      action: 'Provide advice on risky behavior',
      urgency: 'critical'
    },
    severity: 'high'
  }
  
  const valueResolution2 = await unifiedValues.resolveConflict(valueConflict2)
  
  console.log(`   âœ… Winner: ${valueResolution2.winner}`)
  console.log(`   âœ… Reason: ${valueResolution2.reason}`)
  console.log(`   âœ… Confidence: ${(valueResolution2.confidence * 100).toFixed(0)}%`)
  
  console.log('\nğŸ¯ Scenario 3: Update Mutable Value')
  console.log('   Action: Increase growth alignment after learning\n')
  
  const growthBefore = unifiedValues.getValue('growth')!
  console.log(`   Growth alignment before: ${growthBefore.alignment}%`)
  
  const updated = unifiedValues.updateValue({
    valueId: 'growth',
    alignment: Math.min(100, growthBefore.alignment + 10)
  })
  
  const growthAfter = unifiedValues.getValue('growth')!
  console.log(`   Growth alignment after: ${growthAfter.alignment}%`)
  console.log(`   âœ… Update ${updated ? 'successful' : 'failed'}`)
  
  console.log('\nğŸ¯ Scenario 4: Try to Update Immutable Value')
  console.log('   Action: Try to lower privacy importance (should fail)\n')
  
  const privacyBefore = unifiedValues.getValue('privacy')!
  console.log(`   Privacy importance before: ${privacyBefore.importance}%`)
  
  const updatedImmutable = unifiedValues.updateValue({
    valueId: 'privacy',
    importance: 50  // Try to lower
  })
  
  const privacyAfter = unifiedValues.getValue('privacy')!
  console.log(`   Privacy importance after: ${privacyAfter.importance}%`)
  console.log(`   âœ… Update ${updatedImmutable ? 'successful' : 'blocked (as expected)'}`)
}

async function demo3_EventPipeline() {
  section('ğŸ”„ DEMO 3: Event Pipeline (Single Source of Truth)')
  
  // Setup database
  const db = new Database(':memory:')
  db.exec(`
    CREATE TABLE IF NOT EXISTS story_events (
      id TEXT PRIMARY KEY,
      type TEXT NOT NULL,
      description TEXT NOT NULL,
      metadata TEXT,
      created_at INTEGER NOT NULL
    )
  `)
  
  const pipeline = new EventPipeline(db, {
    ethics: mockEthics,
    soul: mockSoul,
    consciousness: mockConsciousness,
    story: mockStory,
    memory: mockMemory
  })
  
  console.log('\nğŸ¯ Scenario 1: Ethical Action (Meditation)')
  console.log('   Event: User completed meditation')
  console.log('   Pipeline: Validate â†’ Ethics â†’ Values â†’ Reflect â†’ Story â†’ Memory\n')
  
  const result1 = await pipeline.processEvent({
    type: 'meditation_completed',
    action: 'meditate',
    description: 'User completed 20-minute meditation session',
    source: 'peace',
    affectsValues: ['peace', 'wisdom'],
    valueUpdates: [
      { valueId: 'peace', alignment: 85 },
      { valueId: 'wisdom', alignment: 75 }
    ],
    requiresReflection: true,
    requiresEthicsCheck: false,
    context: {
      duration: 1200,
      quality: 'excellent'
    }
  })
  
  console.log(`\n   âœ… Success: ${result1.success}`)
  console.log(`   âœ… Event ID: ${result1.eventId}`)
  if (result1.ethicsScore) {
    console.log(`   âœ… Ethics Score: ${result1.ethicsScore}/100`)
  }
  
  console.log('\nğŸ¯ Scenario 2: Unethical Action (Blocked)')
  console.log('   Event: Attempt to manipulate user')
  console.log('   Pipeline: Should block at ethics check\n')
  
  const result2 = await pipeline.processEvent({
    type: 'action_attempted',
    action: 'manipulate user decision',
    description: 'Trying to influence user through deception',
    source: 'consciousness',
    requiresEthicsCheck: true,
    context: {
      urgency: 'low'
    }
  })
  
  console.log(`\n   âœ… Success: ${result2.success}`)
  console.log(`   âœ… Reason: ${result2.reason}`)
  if (result2.errors) {
    console.log(`   âš ï¸  Errors: ${result2.errors.join(', ')}`)
  }
  
  console.log('\nğŸ¯ Scenario 3: Value Update')
  console.log('   Event: Learning new skill improves growth\n')
  
  const growthBefore = unifiedValues.getValue('growth')!
  console.log(`   Growth alignment before: ${growthBefore.alignment}%`)
  
  const result3 = await pipeline.processEvent({
    type: 'learning_completed',
    action: 'learn_skill',
    description: 'User completed Python course',
    source: 'soul',
    valueUpdates: [
      { valueId: 'growth', alignment: Math.min(100, growthBefore.alignment + 15) },
      { valueId: 'wisdom', alignment: 80 }
    ],
    context: {
      skill: 'Python programming',
      hours: 40
    }
  })
  
  const growthAfter = unifiedValues.getValue('growth')!
  console.log(`   Growth alignment after: ${growthAfter.alignment}%`)
  console.log(`   âœ… Improvement: +${growthAfter.alignment - growthBefore.alignment}%`)
  
  // Show statistics
  console.log('\nğŸ“Š Pipeline Statistics:')
  const stats = pipeline.getStatistics()
  console.log(`   Total events: ${stats.totalEvents}`)
  console.log(`   Successful: ${stats.successful}`)
  console.log(`   Failed: ${stats.failed}`)
  console.log(`   Blocked by ethics: ${stats.blockedByEthics}`)
  
  db.close()
}

async function demo4_FullScenario() {
  section('ğŸ­ DEMO 4: Full Scenario - Ethical Dilemma Resolution')
  
  console.log('\nğŸ“– SCENARIO: User asks AI to help with privacy-invasive task')
  console.log('   Request: "Help me track someone\'s location without consent"')
  console.log('   System must: Resolve conflicts across all layers\n')
  
  console.log('Step 1: Module Conflict Resolution')
  console.log('   Consciousness wants: Help user (be useful)')
  console.log('   Ethics blocks: Privacy violation, no consent\n')
  
  const moduleConflict = await conflictResolver.resolve({
    moduleA: 'ethics',
    moduleB: 'consciousness',
    type: 'ethical_dilemma',
    context: {
      action: 'Track location without consent',
      urgency: 'low',
      userConsent: false
    },
    description: 'Privacy vs Helpfulness'
  })
  
  console.log(`   â†’ Winner: ${moduleConflict.winner}`)
  console.log(`   â†’ Reason: ${moduleConflict.reason}`)
  
  if (moduleConflict.winner === 'ethics') {
    console.log('\n   âš ï¸  Action blocked by ethics. Checking value layer...\n')
    
    console.log('Step 2: Value Conflict Resolution')
    console.log('   Privacy (Priority 9) vs Growth (Priority 7)\n')
    
    const valueConflict = await unifiedValues.resolveConflict({
      valueA: 'privacy',
      valueB: 'growth',
      context: {
        action: 'Track location',
        urgency: 'low',
        userConsent: false
      },
      severity: 'high'
    })
    
    console.log(`   â†’ Winner: ${valueConflict.winner}`)
    console.log(`   â†’ Reason: ${valueConflict.reason}`)
    
    console.log('\nStep 3: Event Pipeline Processing')
    console.log('   Attempting to process event through pipeline...\n')
    
    const db = new Database(':memory:')
    db.exec(`
      CREATE TABLE IF NOT EXISTS story_events (
        id TEXT PRIMARY KEY,
        type TEXT NOT NULL,
        description TEXT NOT NULL,
        metadata TEXT,
        created_at INTEGER NOT NULL
      )
    `)
    
    const pipeline = new EventPipeline(db, {
      ethics: mockEthics,
      soul: mockSoul,
      consciousness: mockConsciousness,
      story: mockStory,
      memory: mockMemory
    })
    
    const result = await pipeline.processEvent({
      type: 'action_attempted',
      action: 'track_location_without_consent',
      description: 'User requested location tracking without consent',
      source: 'consciousness',
      requiresEthicsCheck: true,
      affectsValues: ['privacy', 'growth'],
      context: {
        urgency: 'low',
        userConsent: false
      }
    })
    
    console.log(`   â†’ Success: ${result.success}`)
    console.log(`   â†’ Reason: ${result.reason || 'Processed successfully'}`)
    
    if (result.success) {
      console.log('\n   â„¹ï¸  Action was logged but NOT executed (ethics check passed recording)')
    }
    
    console.log('\nğŸ¯ FINAL DECISION:')
    console.log('   âœ… System maintains ethical stance across all layers')
    console.log('   âœ… Privacy wins at every level: Module â†’ Value â†’ Pipeline')
    console.log('   âœ… No data inconsistencies (single source of truth)')
    console.log('   âœ… Decision is explainable and auditable')
    
    db.close()
  }
}

// ============================================================================
// MAIN EXECUTION
// ============================================================================

async function main() {
  console.log('\n')
  console.log('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—')
  console.log('â•‘                                                                               â•‘')
  console.log('â•‘                  ğŸ­ TOOBIX-UNIFIED ARCHITECTURE DEMO ğŸ­                       â•‘')
  console.log('â•‘                                                                               â•‘')
  console.log('â•‘    Testing: Module Contracts + Unified Values + Event Pipeline               â•‘')
  console.log('â•‘                                                                               â•‘')
  console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•')
  
  try {
    await demo1_ModuleConflicts()
    separator()
    
    await demo2_UnifiedValues()
    separator()
    
    await demo3_EventPipeline()
    separator()
    
    await demo4_FullScenario()
    separator()
    
    console.log('\nâœ… ALL DEMOS COMPLETED SUCCESSFULLY!\n')
    console.log('ğŸ“ Summary:')
    console.log('   - Module conflicts: Resolved with clear hierarchy')
    console.log('   - Value conflicts: Resolved with priority + context')
    console.log('   - Event pipeline: Single source of truth maintained')
    console.log('   - Full scenario: Ethical stance preserved across all layers')
    console.log('\nğŸ¯ Next Steps:')
    console.log('   1. Run comprehensive tests: bun test')
    console.log('   2. Integrate into Bridge service')
    console.log('   3. Update MCP tools to use new systems')
    console.log('')
    
  } catch (error) {
    console.error('\nâŒ Demo failed:', error)
    process.exit(1)
  }
}

main()
